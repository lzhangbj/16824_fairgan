{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a9d8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ac7f93c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0\n",
      "    real avg probs:\n",
      "0.78791, 0.01284, 0.05998, 0.02106, 0.02073, 0.02507, 0.07242\n",
      "[[(0, 15794)], [(6, 11959)], [(2, 8273)], [(4, 4344)], [(4, 5354)], [(5, 4938)], [(1, 7652)]]\n",
      "### target cls  0\n",
      "[0.91136426 0.00335261 0.02405048 0.00564277 0.00535132 0.00780015\n",
      " 0.04244041]\n",
      "[0.12823327 0.01677827 0.05212643 0.02272741 0.01847489 0.02685139\n",
      " 0.07003001]\n",
      "[[(0, 1774)], [(6, 490)], [(2, 523)], [(5, 414)], [(4, 369)], [(4, 708)], [(3, 1031)]]\n",
      "### target cls  1\n",
      "[0.65623754 0.08585699 0.08250819 0.01826441 0.03221851 0.05924706\n",
      " 0.06566697]\n",
      "[0.20314592 0.10092703 0.08401936 0.03656876 0.04999086 0.07530073\n",
      " 0.07411156]\n",
      "[[(0, 8320)], [(2, 3572)], [(2, 3429)], [(5, 3133)], [(4, 3280)], [(1, 2298)], [(3, 3870)]]\n",
      "### target cls  2\n",
      "[0.7168818  0.01406391 0.10936074 0.01465214 0.0225999  0.03565217\n",
      " 0.08678912]\n",
      "[0.19313134 0.03792744 0.10441803 0.03938369 0.04537409 0.06037714\n",
      " 0.09059936]\n",
      "[[(0, 3826)], [(3, 1675)], [(4, 1235)], [(2, 1199)], [(2, 999)], [(5, 1853)], [(1, 2188)]]\n",
      "### target cls  3\n",
      "[0.72293323 0.00904723 0.05199511 0.10122106 0.05694311 0.01175741\n",
      " 0.04610194]\n",
      "[0.19712107 0.0266727  0.0700134  0.11362718 0.07536589 0.02910785\n",
      " 0.06261094]\n",
      "[[(0, 2782)], [(2, 773)], [(2, 789)], [(2, 743)], [(6, 666)], [(5, 1040)], [(1, 1276)]]\n",
      "### target cls  4\n",
      "[0.6663257  0.02394671 0.08841    0.06157823 0.07586216 0.02653117\n",
      " 0.05734568]\n",
      "[0.20593107 0.04940399 0.09014637 0.08539649 0.0882567  0.04717608\n",
      " 0.06986289]\n",
      "[[(0, 3124)], [(6, 1245)], [(2, 1214)], [(5, 1028)], [(4, 1136)], [(4, 1229)], [(3, 1869)]]\n",
      "### target cls  5\n",
      "[0.64695376 0.02431855 0.10283878 0.01225801 0.02086589 0.08798993\n",
      " 0.10477432]\n",
      "[0.19400562 0.04981188 0.09233608 0.03304513 0.04082319 0.09676888\n",
      " 0.09646949]\n",
      "[[(0, 6622)], [(6, 5139)], [(2, 4238)], [(5, 2947)], [(4, 2734)], [(4, 1925)], [(3, 2833)]]\n",
      "### target cls  6\n",
      "[0.773088   0.00648719 0.05002049 0.00741628 0.00781445 0.02120833\n",
      " 0.13396464]\n",
      "[0.17302254 0.02161874 0.06804409 0.02614073 0.02017918 0.04639171\n",
      " 0.12145226]\n",
      "\n",
      "class 1\n",
      "    real avg probs:\n",
      "0.03895, 0.81527, 0.02655, 0.00421, 0.03276, 0.07598, 0.00628\n",
      "[[(1, 41)], [(0, 28)], [(2, 12)], [(5, 16)], [(6, 15)], [(4, 16)], [(3, 31)]]\n",
      "### target cls  0\n",
      "[0.17538208 0.58612424 0.07340859 0.01114117 0.04710261 0.07182837\n",
      " 0.0350129 ]\n",
      "[0.09880079 0.19553877 0.07805757 0.02110019 0.06890131 0.0696652\n",
      " 0.05875947]\n",
      "[[(1, 7613)], [(5, 5143)], [(0, 2568)], [(2, 2860)], [(2, 3075)], [(6, 4773)], [(3, 5646)]]\n",
      "### target cls  1\n",
      "[0.02977659 0.85311794 0.01916267 0.00260219 0.0245031  0.06658048\n",
      " 0.0042566 ]\n",
      "[0.06589098 0.18263356 0.04329917 0.01378116 0.0588224  0.10078009\n",
      " 0.01563613]\n",
      "[[(1, 359)], [(5, 122)], [(2, 130)], [(2, 123)], [(4, 113)], [(6, 190)], [(3, 283)]]\n",
      "### target cls  2\n",
      "[0.11434339 0.5864826  0.09756455 0.00917719 0.06655608 0.10891315\n",
      " 0.01696313]\n",
      "[0.10137776 0.19445696 0.08641513 0.02573322 0.08684082 0.09585793\n",
      " 0.02602762]\n",
      "[[(1, 73)], [(4, 29)], [(0, 23)], [(2, 22)], [(2, 24)], [(6, 21)], [(6, 43)]]\n",
      "### target cls  3\n",
      "[0.10435669 0.5607323  0.05757547 0.05524638 0.132219   0.07615344\n",
      " 0.0137166 ]\n",
      "[0.09051749 0.18670836 0.06042442 0.07740249 0.11423036 0.08817167\n",
      " 0.02344318]\n",
      "[[(1, 314)], [(4, 148)], [(2, 78)], [(2, 129)], [(0, 93)], [(3, 108)], [(6, 173)]]\n",
      "### target cls  4\n",
      "[0.08113801 0.5875359  0.06735487 0.02129296 0.14682373 0.08294046\n",
      " 0.01291389]\n",
      "[0.08980448 0.19355777 0.0674492  0.0434558  0.11434254 0.09266745\n",
      " 0.02946367]\n",
      "[[(1, 528)], [(5, 364)], [(0, 184)], [(2, 226)], [(4, 155)], [(6, 298)], [(3, 424)]]\n",
      "### target cls  5\n",
      "[0.06632745 0.6365189  0.04921485 0.00568304 0.04453339 0.18007804\n",
      " 0.0176445 ]\n",
      "[0.08690542 0.19397932 0.06035544 0.01601386 0.07318984 0.13052613\n",
      " 0.0431704 ]\n",
      "[[(1, 41)], [(5, 17)], [(0, 14)], [(2, 17)], [(4, 10)], [(4, 17)], [(3, 34)]]\n",
      "### target cls  6\n",
      "[0.15411068 0.5199363  0.06906371 0.0107296  0.05428349 0.14319469\n",
      " 0.04868156]\n",
      "[0.1151824  0.15557532 0.05758516 0.0303596  0.08473235 0.1050904\n",
      " 0.06966744]\n",
      "\n",
      "class 2\n",
      "    real avg probs:\n",
      "0.18110, 0.03320, 0.48418, 0.02279, 0.08788, 0.12673, 0.06412\n",
      "[[(2, 158)], [(0, 106)], [(5, 45)], [(6, 53)], [(4, 64)], [(1, 54)], [(3, 103)]]\n",
      "### target cls  0\n",
      "[0.2365924  0.02395406 0.48514074 0.01607825 0.05201727 0.11320332\n",
      " 0.07301411]\n",
      "[0.10226694 0.04246126 0.12110288 0.0330658  0.06606233 0.10043808\n",
      " 0.06891185]\n",
      "[[(2, 440)], [(0, 151)], [(0, 121)], [(0, 103)], [(4, 119)], [(6, 173)], [(3, 341)]]\n",
      "### target cls  1\n",
      "[0.15295163 0.09232013 0.4694334  0.01243632 0.08521352 0.14689888\n",
      " 0.04074632]\n",
      "[0.10325215 0.09293942 0.12843667 0.03071886 0.08870371 0.10467145\n",
      " 0.05064705]\n",
      "[[(2, 1869)], [(0, 1029)], [(0, 518)], [(6, 533)], [(4, 656)], [(1, 580)], [(3, 1211)]]\n",
      "### target cls  2\n",
      "[0.1977073  0.02902471 0.5127077  0.01304052 0.06558445 0.11809693\n",
      " 0.06383865]\n",
      "[0.10846024 0.05326811 0.13015622 0.03019394 0.08314463 0.10169145\n",
      " 0.06660087]\n",
      "[[(2, 307)], [(0, 134)], [(4, 88)], [(6, 70)], [(6, 87)], [(5, 87)], [(1, 219)]]\n",
      "### target cls  3\n",
      "[0.17382409 0.01808028 0.4453725  0.07853303 0.13948639 0.08226132\n",
      " 0.06244244]\n",
      "[0.10254885 0.03977543 0.11278985 0.08196174 0.09723402 0.07907739\n",
      " 0.05882767]\n",
      "[[(2, 864)], [(4, 340)], [(0, 248)], [(0, 188)], [(6, 221)], [(6, 243)], [(1, 428)]]\n",
      "### target cls  4\n",
      "[0.15168655 0.02597108 0.4668476  0.04182795 0.16221091 0.1019105\n",
      " 0.04954491]\n",
      "[0.10437335 0.04253561 0.12559767 0.06023281 0.108432   0.09267274\n",
      " 0.05708553]\n",
      "[[(2, 858)], [(5, 366)], [(0, 299)], [(6, 285)], [(4, 310)], [(1, 255)], [(3, 566)]]\n",
      "### target cls  5\n",
      "[0.17144714 0.03142311 0.46939105 0.01526392 0.06491323 0.17676207\n",
      " 0.0707995 ]\n",
      "[0.09906289 0.05214376 0.12085414 0.033381   0.08118515 0.10599809\n",
      " 0.07152201]\n",
      "[[(2, 275)], [(0, 138)], [(6, 89)], [(5, 104)], [(4, 132)], [(1, 115)], [(3, 190)]]\n",
      "### target cls  6\n",
      "[0.21211319 0.01739255 0.4572368  0.01087845 0.04474756 0.13248064\n",
      " 0.12515087]\n",
      "[0.10237953 0.03568868 0.11172218 0.02987736 0.06049909 0.09868527\n",
      " 0.09470852]\n",
      "\n",
      "class 3\n",
      "    real avg probs:\n",
      "0.07596, 0.00351, 0.02039, 0.69682, 0.19155, 0.00404, 0.00774\n",
      "[[(3, 63)], [(0, 37)], [(4, 31)], [(2, 35)], [(6, 34)], [(5, 39)], [(1, 41)]]\n",
      "### target cls  0\n",
      "[0.19600804 0.00542832 0.04420041 0.5779791  0.14564632 0.00817595\n",
      " 0.02256188]\n",
      "[0.11987133 0.01363588 0.05259078 0.15154424 0.09541519 0.01902108\n",
      " 0.0297666 ]\n",
      "[[(3, 43)], [(4, 21)], [(1, 11)], [(2, 16)], [(1, 10)], [(5, 17)], [(6, 22)]]\n",
      "### target cls  1\n",
      "[0.12057908 0.06981482 0.06289947 0.49428406 0.20262967 0.03082255\n",
      " 0.01897032]\n",
      "[0.10610614 0.08189554 0.06774789 0.16611707 0.11475652 0.04103977\n",
      " 0.02285998]\n",
      "[[(3, 195)], [(4, 111)], [(0, 73)], [(2, 107)], [(6, 106)], [(5, 98)], [(1, 113)]]\n",
      "### target cls  2\n",
      "[0.14862996 0.00944086 0.05733245 0.5412094  0.2013987  0.01424403\n",
      " 0.02774429]\n",
      "[0.11762349 0.02214415 0.05924339 0.1591383  0.11583388 0.03046669\n",
      " 0.04550986]\n",
      "[[(3, 5674)], [(4, 4446)], [(0, 3744)], [(2, 3932)], [(6, 3761)], [(5, 2990)], [(1, 3034)]]\n",
      "### target cls  3\n",
      "[0.07112959 0.00204641 0.01490787 0.72406656 0.17953295 0.00229483\n",
      " 0.00602316]\n",
      "[0.10293996 0.01111898 0.03473585 0.16052178 0.11990406 0.01034176\n",
      " 0.01590319]\n",
      "[[(3, 1550)], [(4, 1242)], [(0, 874)], [(2, 930)], [(6, 899)], [(5, 753)], [(1, 765)]]\n",
      "### target cls  4\n",
      "[0.07453328 0.00535692 0.03064243 0.6368969  0.23685531 0.00617313\n",
      " 0.00954226]\n",
      "[0.09950384 0.01964461 0.05171235 0.16138901 0.12439258 0.01973842\n",
      " 0.02023979]\n",
      "[[(3, 66)], [(4, 37)], [(0, 24)], [(2, 31)], [(6, 27)], [(5, 27)], [(1, 40)]]\n",
      "### target cls  5\n",
      "[0.12454533 0.02019514 0.07457145 0.52061415 0.19370686 0.04583197\n",
      " 0.02053518]\n",
      "[0.10536518 0.03048636 0.05477777 0.14587453 0.11449853 0.06459203\n",
      " 0.02001362]\n",
      "[[(3, 26)], [(0, 15)], [(4, 14)], [(6, 9)], [(6, 13)], [(5, 14)], [(1, 14)]]\n",
      "### target cls  6\n",
      "[0.1807847  0.01030467 0.0630412  0.56009066 0.12696871 0.02052866\n",
      " 0.03828136]\n",
      "[0.11605586 0.01922252 0.06113742 0.15944277 0.07720833 0.04266657\n",
      " 0.03904242]\n",
      "\n",
      "class 4\n",
      "    real avg probs:\n",
      "0.05342, 0.03079, 0.07464, 0.13906, 0.67286, 0.02235, 0.00689\n",
      "[[(4, 58)], [(3, 26)], [(2, 19)], [(2, 17)], [(6, 15)], [(5, 31)], [(6, 26)]]\n",
      "### target cls  0\n",
      "[0.12107806 0.0267964  0.08542968 0.12496059 0.61397994 0.0193059\n",
      " 0.00844953]\n",
      "[0.12501214 0.05093941 0.09698935 0.12217467 0.1966337  0.03527721\n",
      " 0.01204658]\n",
      "[[(4, 482)], [(1, 214)], [(2, 169)], [(2, 131)], [(0, 137)], [(5, 143)], [(6, 396)]]\n",
      "### target cls  1\n",
      "[0.0537644  0.14393766 0.09548687 0.05417181 0.59681904 0.04889282\n",
      " 0.0069271 ]\n",
      "[0.0702629  0.12156633 0.08851662 0.07869663 0.18725112 0.06613149\n",
      " 0.01590436]\n",
      "[[(4, 737)], [(2, 338)], [(2, 234)], [(0, 199)], [(5, 179)], [(5, 235)], [(6, 392)]]\n",
      "### target cls  2\n",
      "[0.08677089 0.03956836 0.14587685 0.09024946 0.5862556  0.03991719\n",
      " 0.01136204]\n",
      "[0.09262549 0.06395069 0.106757   0.1035748  0.18323322 0.06136242\n",
      " 0.01706685]\n",
      "[[(4, 2250)], [(3, 1748)], [(0, 949)], [(2, 980)], [(6, 713)], [(5, 966)], [(6, 831)]]\n",
      "### target cls  3\n",
      "[0.05203552 0.01164643 0.04735938 0.22453214 0.65014035 0.00832154\n",
      " 0.0059648 ]\n",
      "[0.07930386 0.03777548 0.07100862 0.14021848 0.16715603 0.02220551\n",
      " 0.01568766]\n",
      "[[(4, 4757)], [(3, 2589)], [(2, 1950)], [(0, 1357)], [(1, 1250)], [(5, 1755)], [(6, 2709)]]\n",
      "### target cls  4\n",
      "[0.04701604 0.02516373 0.06988169 0.12034804 0.71255845 0.01897685\n",
      " 0.0060564 ]\n",
      "[0.07498021 0.05663108 0.08666054 0.12241452 0.1882119  0.04267169\n",
      " 0.01362799]\n",
      "[[(4, 335)], [(2, 135)], [(2, 118)], [(0, 85)], [(0, 94)], [(6, 85)], [(6, 203)]]\n",
      "### target cls  5\n",
      "[0.05908699 0.05459199 0.12835883 0.06919026 0.5924534  0.0851141\n",
      " 0.0112045 ]\n",
      "[0.07509183 0.08319113 0.0918652  0.09231649 0.19337296 0.09512831\n",
      " 0.01965735]\n",
      "[[(4, 39)], [(2, 15)], [(2, 11)], [(2, 8)], [(6, 10)], [(5, 12)], [(1, 13)]]\n",
      "### target cls  6\n",
      "[0.1302208  0.05839163 0.14666604 0.08342378 0.49541864 0.04903406\n",
      " 0.03684506]\n",
      "[0.10555366 0.09520397 0.09483878 0.08236523 0.15485525 0.06171188\n",
      " 0.04881497]\n",
      "\n",
      "class 5\n",
      "    real avg probs:\n",
      "0.06296, 0.05803, 0.09128, 0.00287, 0.02062, 0.73285, 0.03140\n",
      "[[(5, 119)], [(0, 50)], [(2, 50)], [(6, 45)], [(1, 42)], [(4, 62)], [(3, 105)]]\n",
      "### target cls  0\n",
      "[0.14696716 0.05224979 0.13572647 0.00308783 0.01733277 0.58388317\n",
      " 0.06075283]\n",
      "[0.10704675 0.08638558 0.09529328 0.00769414 0.02806705 0.18260165\n",
      " 0.08014275]\n",
      "[[(5, 1781)], [(1, 1091)], [(2, 825)], [(0, 619)], [(4, 579)], [(6, 934)], [(3, 1612)]]\n",
      "### target cls  1\n",
      "[0.05190308 0.15568607 0.07649551 0.00257612 0.02338216 0.67190367\n",
      " 0.01805273]\n",
      "[0.07725376 0.1361694  0.08917118 0.01013291 0.0467774  0.19654988\n",
      " 0.04003264]\n",
      "[[(5, 1260)], [(2, 724)], [(0, 475)], [(6, 410)], [(4, 404)], [(4, 541)], [(3, 1112)]]\n",
      "### target cls  2\n",
      "[0.10827406 0.04336601 0.1611954  0.00300232 0.02606683 0.60669595\n",
      " 0.05139922]\n",
      "[0.09909538 0.0755885  0.10543186 0.0093788  0.04878705 0.19255655\n",
      " 0.0673313 ]\n",
      "[[(5, 81)], [(2, 34)], [(2, 26)], [(6, 19)], [(4, 22)], [(6, 24)], [(3, 41)]]\n",
      "### target cls  3\n",
      "[0.12204228 0.04846811 0.15093318 0.0297022  0.07213348 0.5338576\n",
      " 0.04286317]\n",
      "[0.10495971 0.06951222 0.08629593 0.05323029 0.08310142 0.17212303\n",
      " 0.05852202]\n",
      "[[(5, 421)], [(2, 219)], [(2, 136)], [(0, 99)], [(0, 119)], [(6, 151)], [(3, 278)]]\n",
      "### target cls  4\n",
      "[0.07340512 0.05957917 0.15094492 0.01402599 0.08523769 0.58588684\n",
      " 0.03092039]\n",
      "[0.07985204 0.08279111 0.09483805 0.0358104  0.09848253 0.19904117\n",
      " 0.05012042]\n",
      "[[(5, 6840)], [(2, 3569)], [(2, 2171)], [(0, 2315)], [(4, 1994)], [(4, 3179)], [(3, 6365)]]\n",
      "### target cls  5\n",
      "[0.05154839 0.03739005 0.07444211 0.00188635 0.01468427 0.7930069\n",
      " 0.02704076]\n",
      "[0.07977024 0.07364048 0.08896497 0.01069232 0.03919226 0.19943999\n",
      " 0.05324656]\n",
      "[[(5, 352)], [(2, 167)], [(0, 133)], [(6, 133)], [(1, 155)], [(4, 188)], [(3, 322)]]\n",
      "### target cls  6\n",
      "[0.1239012  0.01987757 0.14280963 0.00328882 0.01438683 0.59559405\n",
      " 0.10014176]\n",
      "[0.10118406 0.04070668 0.09615771 0.01958285 0.03527757 0.18633631\n",
      " 0.09626463]\n",
      "\n",
      "class 6\n",
      "    real avg probs:\n",
      "0.24264, 0.00811, 0.07041, 0.00431, 0.00581, 0.05391, 0.61480\n",
      "[[(6, 294)], [(0, 277)], [(2, 231)], [(5, 198)], [(4, 129)], [(4, 122)], [(3, 207)]]\n",
      "### target cls  0\n",
      "[0.2932756  0.00503361 0.05985045 0.00244814 0.00400424 0.03208411\n",
      " 0.603304  ]\n",
      "[0.11710469 0.01958597 0.06940864 0.0083013  0.01203349 0.0585599\n",
      " 0.15657355]\n",
      "[[(6, 100)], [(0, 54)], [(0, 29)], [(5, 37)], [(1, 42)], [(4, 53)], [(3, 62)]]\n",
      "### target cls  1\n",
      "[0.20440874 0.06411941 0.09909637 0.01346784 0.01764407 0.11049019\n",
      " 0.49077344]\n",
      "[0.09819187 0.08367963 0.0860507  0.03037461 0.03154774 0.09781324\n",
      " 0.15102871]\n",
      "[[(6, 627)], [(0, 484)], [(2, 413)], [(5, 390)], [(4, 284)], [(4, 276)], [(3, 464)]]\n",
      "### target cls  2\n",
      "[0.2556045  0.00919706 0.10506526 0.00507309 0.00775589 0.06117483\n",
      " 0.5561295 ]\n",
      "[0.11276191 0.02600183 0.08867977 0.01915522 0.01706669 0.07515761\n",
      " 0.15185057]\n",
      "[[(6, 76)], [(0, 61)], [(2, 38)], [(5, 23)], [(4, 28)], [(5, 27)], [(1, 49)]]\n",
      "### target cls  3\n",
      "[0.26691797 0.01748646 0.1108337  0.04211326 0.03224629 0.034555\n",
      " 0.49584734]\n",
      "[0.09008787 0.03883523 0.09222397 0.0516841  0.03806238 0.03969238\n",
      " 0.1383967 ]\n",
      "[[(6, 107)], [(0, 71)], [(2, 52)], [(5, 44)], [(4, 47)], [(1, 33)], [(3, 47)]]\n",
      "### target cls  4\n",
      "[0.2388292  0.01886823 0.11609657 0.02477665 0.02748145 0.06497891\n",
      " 0.50896895]\n",
      "[0.10950727 0.03901942 0.09252589 0.04437565 0.03645354 0.07526908\n",
      " 0.15309   ]\n",
      "[[(6, 568)], [(0, 371)], [(2, 244)], [(2, 234)], [(1, 295)], [(4, 316)], [(3, 448)]]\n",
      "### target cls  5\n",
      "[0.20759337 0.00882426 0.08632835 0.00327059 0.00496144 0.11072273\n",
      " 0.57829934]\n",
      "[0.11455087 0.02027381 0.08255368 0.01447891 0.00920974 0.10552815\n",
      " 0.17016515]\n",
      "[[(6, 1861)], [(0, 1677)], [(2, 1323)], [(5, 1230)], [(4, 812)], [(4, 842)], [(3, 1424)]]\n",
      "### target cls  6\n",
      "[0.24225807 0.00400242 0.04972791 0.00144996 0.00274104 0.034683\n",
      " 0.6651371 ]\n",
      "[0.1281012  0.0147303  0.06271845 0.00630394 0.00794504 0.06312149\n",
      " 0.16283962]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.3738933 0.39576125\n",
      "0.95564836 0.38754764\n",
      "\n",
      "1\n",
      "0.8488126 0.67901945\n",
      "0.62233305 0.48230198\n",
      "\n",
      "2\n",
      "0.39174178 0.30893883\n",
      "0.13982195 0.3537069\n",
      "\n",
      "3\n",
      "0.7449127 0.51963747\n",
      "0.4617889 0.37796044\n",
      "\n",
      "4\n",
      "0.54943407 0.32233837\n",
      "0.44066697 0.29421028\n",
      "\n",
      "5\n",
      "0.63018245 0.4408756\n",
      "0.55523986 0.3253511\n",
      "\n",
      "6\n",
      "0.5122488 0.2836348\n",
      "0.20193142 0.57508683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_1 = 'fairface_train_probs.npy'\n",
    "target_1 = 'fairface_train_targets.npy'\n",
    "probs = np.load(prob_1)\n",
    "probs = softmax(probs, axis=1)\n",
    "targets = np.load(target_1)\n",
    "preds = np.argmax(probs, axis=1)\n",
    "pred_probs = np.max(probs, axis=1)\n",
    "\n",
    "confusion = confusion_matrix(targets, preds)\n",
    "confusion_rowwise = confusion / confusion.sum(axis=1, keepdims=True)\n",
    "confusion_colwise = confusion / confusion.sum(axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "# calculate correction matrix\n",
    "correction_matrix = np.zeros((7,7), dtype=np.float32)\n",
    "for cls_id in range(7):\n",
    "\n",
    "    cls_real_mask = targets == cls_id\n",
    "    cls_pred_mask = preds == cls_id\n",
    "    cls_real_pred_mask = cls_real_mask & cls_pred_mask\n",
    "    \n",
    "    precision = np.sum(cls_real_pred_mask.astype(np.float32)) / np.sum(cls_pred_mask.astype(np.float32))\n",
    "    recall = np.sum(cls_real_pred_mask.astype(np.float32)) / np.sum(cls_real_mask.astype(np.float32))\n",
    "\n",
    "    cls_real_probs = probs[cls_real_mask]\n",
    "    cls_real_probs_mean = np.mean(cls_real_probs, axis=0)\n",
    "    cls_real_probs_std  = np.std(cls_real_probs, axis=0)\n",
    "    \n",
    "    cls_pred_probs = probs[cls_pred_mask]\n",
    "    cls_pred_probs_mean = np.mean(cls_pred_probs, axis=0)\n",
    "    cls_pred_probs_std  = np.std(cls_pred_probs, axis=0)\n",
    "    \n",
    "    print(f\"class {cls_id}\")\n",
    "#     print(f\"precision:\\t{precision}\\nrecall:\\t\\t{recall}\")\n",
    "#     st = ', '.join([f'{x:.5f}' for x in confusion_rowwise[cls_id, :].tolist()])\n",
    "#     print(f\"### pred probs:\\n{st}\")\n",
    "#     st = ', '.join([f'{x:.5f}' for x in cls_real_probs_mean.tolist()])\n",
    "#     print(f\"    pred avg probs:\\n{st}\")\n",
    "#     st = ', '.join([f'{x:.5f}' for x in cls_real_probs_std.tolist()])\n",
    "#     print(f\"    pred std probs:\\n{st}\")\n",
    "#     st = ', '.join([f'{x:.5f}' for x in confusion_colwise[:, cls_id].tolist()])\n",
    "#     print(f\"### real probs:\\n{st}\")\n",
    "    st = ', '.join([f'{x:.5f}' for x in cls_pred_probs_mean.tolist()])\n",
    "    print(f\"    real avg probs:\\n{st}\")\n",
    "#     st = ', '.join([f'{x:.5f}' for x in cls_pred_probs_std.tolist()])\n",
    "#     print(f\"    real std probs:\\n{st}\")\n",
    "#     print()\n",
    "    \n",
    "    for j in range(7):\n",
    "    \n",
    "        cls_2_mask = targets == j\n",
    "        cls_2_mispred_mask = cls_pred_mask & cls_2_mask\n",
    "        cls_2_probs = probs[cls_2_mispred_mask]\n",
    "        sorted_indices = cls_2_probs.argsort(axis=1)[:, ::-1]\n",
    "        print([Counter(sorted_indices[:, k].tolist()).most_common(1) for k in range(7)])\n",
    "        print(\"### target cls \", j)\n",
    "        print(cls_2_probs.mean(axis=0))\n",
    "        correction_matrix[cls_id,j] = cls_2_probs.mean(axis=0)[j] - cls_2_probs.std(axis=0)[j]\n",
    "        print(cls_2_probs.std(axis=0))\n",
    "    print()\n",
    "\n",
    "corrected_preds = np.zeros_like(preds)\n",
    "second_corrected_preds = np.zeros_like(preds)\n",
    "for cls_id in range(7):\n",
    "    cls_pred_mask = preds == cls_id\n",
    "    cls_pred_probs = probs[cls_pred_mask]\n",
    "    \n",
    "    cls_other_pred_probs = cls_pred_probs.copy()\n",
    "    cls_other_pred_probs[:, cls_id] = 0.\n",
    "    \n",
    "    top1_cls = cls_other_pred_probs.argmax(axis=1)\n",
    "    top1_cls_prob = cls_other_pred_probs.max(axis=1)\n",
    "    top1_stand = correction_matrix[cls_id, top1_cls]\n",
    "    labels = np.where(top1_cls_prob>=top1_stand, top1_cls, cls_id)\n",
    "    corrected_preds[cls_pred_mask] = labels\n",
    "    \n",
    "    cls_other_pred_probs[:, top1_cls] = 0.\n",
    "    top2_cls = cls_other_pred_probs.argmax(axis=1)\n",
    "    top2_cls_prob = cls_other_pred_probs.max(axis=1)\n",
    "    top2_stand = correction_matrix[cls_id, top2_cls]\n",
    "    labels = np.where(top2_cls_prob>=top2_stand, top2_cls, cls_id)\n",
    "    second_corrected_preds[cls_pred_mask] = labels\n",
    "\n",
    "for cls_id in range(7):\n",
    "\n",
    "    cls_real_mask = targets == cls_id\n",
    "    \n",
    "    \n",
    "    cls_pred_mask = preds == cls_id\n",
    "    cls_real_pred_mask = cls_real_mask & cls_pred_mask\n",
    "    \n",
    "    old_precision = np.sum(cls_real_pred_mask.astype(np.float32)) / np.sum(cls_pred_mask.astype(np.float32))\n",
    "    old_recall = np.sum(cls_real_pred_mask.astype(np.float32)) / np.sum(cls_real_mask.astype(np.float32))\n",
    "    \n",
    "    \n",
    "    cls_pred_mask = corrected_preds == cls_id\n",
    "#     cls_second_pred_mask = second_corrected_preds == cls_id\n",
    "#     cls_pred_mask = cls_pred_mask | cls_second_pred_mask\n",
    "    cls_real_pred_mask = cls_real_mask & cls_pred_mask\n",
    "    \n",
    "    precision = np.sum(cls_real_pred_mask.astype(np.float32)) / np.sum(cls_pred_mask.astype(np.float32))\n",
    "    recall = np.sum(cls_real_pred_mask.astype(np.float32)) / np.sum(cls_real_mask.astype(np.float32))\n",
    "    print(cls_id)\n",
    "    print(old_precision, precision)\n",
    "    print(old_recall, recall)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51591dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering analysis\n",
    "def print_distances(embeddings_file, labels_file):\n",
    "    embeddings = np.load(embeddings_file)\n",
    "    normed_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    labels = np.load(labels_file)[:, 0]\n",
    "\n",
    "    cls_normed_embeddings = []\n",
    "    for i in range(7):\n",
    "        curr_cls_mask = labels==i\n",
    "        curr_cls_normed_embeddings = normed_embeddings[curr_cls_mask]\n",
    "        cls_normed_embeddings.append(curr_cls_normed_embeddings)\n",
    "\n",
    "    cls_clusterings_mean = np.array([curr_cls_normed_embeddings.mean(axis=0) for curr_cls_normed_embeddings in cls_normed_embeddings])\n",
    "    cls_clusterings_std = np.array([curr_cls_normed_embeddings.std(axis=0) for curr_cls_normed_embeddings in cls_normed_embeddings])\n",
    "\n",
    "    race_list = ['White', 'Black', 'Latino hispanic', 'East asian', 'Southeast asian', 'Indian', 'Middle eastern']\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "    pairwise_distances = np.linalg.norm(cls_clusterings_mean[:, None, :] - cls_clusterings_mean[None, :, :], axis=2)\n",
    "    weighted_pairwise_distances = pairwise_distances.copy()\n",
    "    weighted_pairwise_distances[:, 0] *= 4\n",
    "    mean_distances = weighted_pairwise_distances.sum(axis=1)/6\n",
    "    \n",
    "    x = PrettyTable([\"\", 'avg'] + race_list)\n",
    "    for i, row in enumerate(pairwise_distances):\n",
    "        row = [\"{0:0.2f}\".format(i) for i in row.tolist()]\n",
    "        mean_dist = \"{0:0.2f}\".format(mean_distances[i])\n",
    "        x.add_row([race_list[i], mean_dist] + row)\n",
    "    print(x)\n",
    "\n",
    "def print_center_distances(cluster_file):\n",
    "    embeddings = np.load(cluster_file)\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    distances = cdist(embeddings, embeddings)\n",
    "    \n",
    "    race_list = ['White', 'Black', 'Latino hispanic', 'East asian', 'Southeast asian', 'Indian', 'Middle eastern']\n",
    "    x = PrettyTable([\"\"] + race_list)\n",
    "    for i, row in enumerate(pairwise_distances):\n",
    "        row = [\"{0:0.2f}\".format(i) for i in row.tolist()]\n",
    "        mean_dist = \"{0:0.2f}\".format(mean_distances[i])\n",
    "        x.add_row([race_list[i], mean_dist] + row)\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77e1bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|                 | avg  | White | Black | Latino hispanic | East asian | Southeast asian | Indian | Middle eastern |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|      White      | 0.56 |  0.00 |  0.80 |       0.36      |    0.67    |       0.67      |  0.63  |      0.26      |\n",
      "|      Black      | 1.04 |  0.80 |  0.00 |       0.57      |    0.76    |       0.58      |  0.40  |      0.72      |\n",
      "| Latino hispanic | 0.60 |  0.36 |  0.57 |       0.00      |    0.56    |       0.46      |  0.33  |      0.24      |\n",
      "|    East asian   | 0.94 |  0.67 |  0.76 |       0.56      |    0.00    |       0.24      |  0.69  |      0.69      |\n",
      "| Southeast asian | 0.85 |  0.67 |  0.58 |       0.46      |    0.24    |       0.00      |  0.53  |      0.64      |\n",
      "|      Indian     | 0.82 |  0.63 |  0.40 |       0.33      |    0.69    |       0.53      |  0.00  |      0.47      |\n",
      "|  Middle eastern | 0.63 |  0.26 |  0.72 |       0.24      |    0.69    |       0.64      |  0.47  |      0.00      |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|                 | avg  | White | Black | Latino hispanic | East asian | Southeast asian | Indian | Middle eastern |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|      White      | 0.65 |  0.00 |  0.89 |       0.42      |    0.72    |       0.75      |  0.74  |      0.36      |\n",
      "|      Black      | 1.14 |  0.89 |  0.00 |       0.65      |    0.74    |       0.59      |  0.51  |      0.78      |\n",
      "| Latino hispanic | 0.68 |  0.42 |  0.65 |       0.00      |    0.55    |       0.48      |  0.44  |      0.28      |\n",
      "|    East asian   | 0.96 |  0.72 |  0.74 |       0.55      |    0.00    |       0.30      |  0.64  |      0.65      |\n",
      "| Southeast asian | 0.92 |  0.75 |  0.59 |       0.48      |    0.30    |       0.00      |  0.51  |      0.64      |\n",
      "|      Indian     | 0.94 |  0.74 |  0.51 |       0.44      |    0.64    |       0.51      |  0.00  |      0.55      |\n",
      "|  Middle eastern | 0.72 |  0.36 |  0.78 |       0.28      |    0.65    |       0.64      |  0.55  |      0.00      |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|                 | avg  | White | Black | Latino hispanic | East asian | Southeast asian | Indian | Middle eastern |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|      White      | 0.14 |  0.00 |  0.20 |       0.07      |    0.19    |       0.18      |  0.13  |      0.07      |\n",
      "|      Black      | 0.30 |  0.20 |  0.00 |       0.20      |    0.24    |       0.21      |  0.15  |      0.21      |\n",
      "| Latino hispanic | 0.16 |  0.07 |  0.20 |       0.00      |    0.16    |       0.14      |  0.11  |      0.08      |\n",
      "|    East asian   | 0.28 |  0.19 |  0.24 |       0.16      |    0.00    |       0.07      |  0.22  |      0.21      |\n",
      "| Southeast asian | 0.25 |  0.18 |  0.21 |       0.14      |    0.07    |       0.00      |  0.18  |      0.19      |\n",
      "|      Indian     | 0.22 |  0.13 |  0.15 |       0.11      |    0.22    |       0.18      |  0.00  |      0.11      |\n",
      "|  Middle eastern | 0.18 |  0.07 |  0.21 |       0.08      |    0.21    |       0.19      |  0.11  |      0.00      |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|                 | avg  | White | Black | Latino hispanic | East asian | Southeast asian | Indian | Middle eastern |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n",
      "|      White      | 0.73 |  0.00 |  1.11 |       0.34      |    0.86    |       0.86      |  0.89  |      0.30      |\n",
      "|      Black      | 1.52 |  1.11 |  0.00 |       0.92      |    1.03    |       0.91      |  0.82  |      1.03      |\n",
      "| Latino hispanic | 0.76 |  0.34 |  0.92 |       0.00      |    0.72    |       0.64      |  0.64  |      0.29      |\n",
      "|    East asian   | 1.22 |  0.86 |  1.03 |       0.72      |    0.00    |       0.43      |  0.89  |      0.83      |\n",
      "| Southeast asian | 1.16 |  0.86 |  0.91 |       0.64      |    0.43    |       0.00      |  0.77  |      0.80      |\n",
      "|      Indian     | 1.24 |  0.89 |  0.82 |       0.64      |    0.89    |       0.77      |  0.00  |      0.77      |\n",
      "|  Middle eastern | 0.82 |  0.30 |  1.03 |       0.29      |    0.83    |       0.80      |  0.77  |      0.00      |\n",
      "+-----------------+------+-------+-------+-----------------+------------+-----------------+--------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print_distances('cls_fairface-val_embeddings.npy', 'cls_fairface-val_labels.npy')\n",
    "print_distances('fixmatch_fairface-val_embeddings.npy', 'fixmatch_fairface-val_labels.npy')\n",
    "print_distances('ssp_fairface-val_embeddings.npy', 'ssp_fairface-val_labels.npy')\n",
    "print_distances('cluster_fairface-val_embeddings.npy', 'cluster_fairface-val_labels.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
